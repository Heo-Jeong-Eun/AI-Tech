{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b4487a",
   "metadata": {},
   "source": [
    "# chapter 2. Machine Learning Starting with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c7ce9",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Data Encoding\n",
    "\n",
    "**데이터 전처리**는 ML 알고리즘만큼 중요하다. **어떤 데이터를 입력으로 가지느냐에 따라 결과도 크게 달라지기 때문**이다. <br>\n",
    "\n",
    "결손값, NaN, Null 값은 허용되지 않는다. <br>\n",
    "Null 값은 고정된 다른 값으로 변환해야 한다. Null을 어떻게 처리해야 하는지는 경우에 따라 다르다. <br>\n",
    "피처 값 중 Null이 얼마 되지 않는다면 피처의 평균값으로 대체할 수 있다. 하지만 Null 값이 대부분이라면 오히려 해당 피처는 드롭하는 것이 좋다. <br> \n",
    "가장 처리하기 힘든 경우는 Null이 일정 수준 이상 되는 경우이다. 해당 피처가 중요도 높은 피처이고 Null을 단순히 피처의 평균값으로 대체할 경우 예측 왜곡이 심할 수 있기 때문에 더 정밀한 대체값을 선정해야 한다. <br>\n",
    "\n",
    "**머신러닝을 위한 대표적 인코딩 방식**은 레이블 인코딩(Label Encoding)과 원-핫 인코딩(One-Hot Encoding)이다. <br>\n",
    "**레이블 인코딩**은 **카테고리 피처를 코드형 숫자 값으로 변환**하는 것이다. <br>\n",
    "\n",
    "**레이블 인코딩** <br>\n",
    "사이킷런의 레이블 인코딩은 **LabelEncoder 클래스로 구현**한다. <br>\n",
    "LabelEncoder를 객체로 생성한 후 **fit()과 transform()을 호출**해 레이블 인코딩을 수행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c92e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값 :  [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변환값 : ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17f04e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스 :  ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print('인코딩 클래스 : ', encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4c91e",
   "metadata": {},
   "source": [
    "**inverse_transform()** 을 통해 인코딩된 값을 **다시 디코딩**할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0267c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본값 :  ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "print('디코딩 원본값 : ', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fec54f",
   "metadata": {},
   "source": [
    "레이블 인코딩은 간단하게 문자열 값을 숫자형 카테고리 값으로 변환한다. <br>\n",
    "레이블 인코딩이 일괄적인 숫자 값으로 변환 되며 몇몇 ML 알고리즘에는 이를 적용할 경우 **예측 성능이 떨어지는 상황**이 발생한다. <br>\n",
    "숫자 값의 경우 크고 작음에 대한 특성이 작용하기 때문이다. <br>\n",
    "따라서 **레이블 인코딩은 선형 회귀와 같은 ML 알고리즘에는 적용하지 않아야 한다.** <br>\n",
    "트리 계열의 ML 알고리즘은 숫자의 이러한 특성을 반영하지 않으므로 레이블 인코딩을 해도 상관없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0066c7b",
   "metadata": {},
   "source": [
    "**One-Hot Encoging** <br>\n",
    "\n",
    "One-Hot Encoging은 **피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 column에만 1을 표시하고 나머지 column에는 0을 표시하는 방식**이다. <br>\n",
    "**행 형태로 있는 피처의 고유 값을 열 형태로 차원 변환**한 뒤, **고유 값에 해당하는 column에만 1을 표시하고 나머지 column에는 0을 표시**한다. <br> \n",
    "One-Hot Encoging은 사이킷런에서 **OneHotEncoder 클래스**로 변환이 가능하다. <br>\n",
    "입력값으로 2차원 데이터가 필요하며 OneHotEncoder를 이용해 **변환한 값이 희소 행렬(Sparse Matirx)형태**이므로 이를 다시 **toarray() 메서드를 이용해 밀집 행렬(Dense Matrix)로 변환**해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4430cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoging Data\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "One-Hot Encoging Data 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 2차원 ndarray로 변환한다. \n",
    "items = np.array(items).reshape(-1, 1)\n",
    "\n",
    "# One-Hot Encoging 적용\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(items)\n",
    "oh_labels = oh_encoder.transform(items)\n",
    "\n",
    "# OneHotEncoder로 변환한 결과는 희소행렬이므로 toarray()를 이용해 밀집 행렬로 변환\n",
    "print('One-Hot Encoging Data')\n",
    "print(oh_labels.toarray())\n",
    "print('One-Hot Encoging Data 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121b3211",
   "metadata": {},
   "source": [
    "Pandas에는 One-Hot Encoging을 더 쉽게 지원하는 **get_dummies()** 라는 API가 있다. <br>\n",
    "문자열 카테고리 값을 숫자형으로 변환할 필요 없이 바로 변환이 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05b6cd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items_TV</th>\n",
       "      <th>items_냉장고</th>\n",
       "      <th>items_믹서</th>\n",
       "      <th>items_선풍기</th>\n",
       "      <th>items_전자레인지</th>\n",
       "      <th>items_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   items_TV  items_냉장고  items_믹서  items_선풍기  items_전자레인지  items_컴퓨터\n",
       "0         1          0         0          0            0          0\n",
       "1         0          1         0          0            0          0\n",
       "2         0          0         0          0            1          0\n",
       "3         0          0         0          0            0          1\n",
       "4         0          0         0          1            0          0\n",
       "5         0          0         0          1            0          0\n",
       "6         0          0         1          0            0          0\n",
       "7         0          0         1          0            0          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'items' : ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e6d68",
   "metadata": {},
   "source": [
    "### 피처 스케일링과 정규화\n",
    "\n",
    "**서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업**을 피처 스케일링이라고 한다. <br>\n",
    "대표적인 방법으로는 **표준화(Standardization)** 과 **정규화(Normalization)** 이 있다. <br>\n",
    "\n",
    "**표준화**는 데이터의 각각의 피처 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것이다. <br>\n",
    "<img src = 'image/Standardization.jpg' alt = 'Standardization' width='400' height='400'> <br>\n",
    "\n",
    "**정규화**는 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념이다. <br>\n",
    "개별 데이터의 크기를 모두 똑같은 단위로 변경하는 것이다. <br>\n",
    "<img src = 'image/Normalization.jpg' alt = 'Normalization' width='400' height='400'> <br>\n",
    "\n",
    "**사이킷런의 Normalizer 모듈은 선형대수에서의 정규화 개념이 적용**되었으며, **개별 벡터의 크기를 맞추기 위해 변환하는 것을 의미**한다. <br>\n",
    "개별 벡터를 모든 피처 벡터의 크기로 나누어 준다. <br>\n",
    "<img src = 'image/Feature Scaling.jpg' alt = 'Feature Scaling' width='370' height='370'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8448d53",
   "metadata": {},
   "source": [
    "### StandardScaler\n",
    "\n",
    "StandardScaler는 **표준화를 쉽게 지원하기 위한 클래스**이다. <br>\n",
    "**개별 피처를 평균이 0이고 분산이 1인 값으로 변환한다.** <br>\n",
    "사이킷런에서 구현한 **RBF 커널을 이용하는 서포트 벡터 머신이나 선형회귀, 로지스틱 회귀는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현**되었기 때문에 **사전에 표준화를 적용하는 것은 예측 성능 향상에 중요한 요소**가 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0987b45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "feature들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트를 로딩하고 DataFrame으로 변환한다. \n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data = iris_data, columns = iris.feature_names)\n",
    "\n",
    "print('feature들의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('feature들의 분산 값')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b13ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "feature들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# StandardScaler로 데이터 세트 변환, fit()과 transform() 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform() 시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환되어 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "print('feature들의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('feature들의 분산 값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b95739",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    "\n",
    "MinMaxScaler는 **데이터 값을 0과 1 사이의 범위 값으로 변환**한다. 음수 값이 있으면 -1에서 1값으로 변환한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86c5324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 최소값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "feature들의 최대값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# MinMaxScaler로 데이터 세트 변환, fit()과 transform() 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform() 시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환되어 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "print('feature들의 최소값')\n",
    "print(iris_df_scaled.min())\n",
    "print('feature들의 최대값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4c68e",
   "metadata": {},
   "source": [
    "### 학습 데이터와 테스트 데이터 스케일링 변환 시 유의점\n",
    "\n",
    "StandardScaler나 MinMaxScaler와 같은 Sclaer 객체를 이용해 데이터의 스케일링 변환 시 fit(), transform(), fit_transform() 메서드를 이용한다. <br>\n",
    "fit()은 데이터 변환을 위한 기준 설정을 적용하며 transform()은 이렇게 설정된 정보를 이용해 데이터를 변환한다. <br>\n",
    "**fit_transform()은 fit()과 transform()을 한번에 적용**하는 기능을 수행한다. <br>\n",
    "\n",
    "Scaler 객체를 이용해 학습 데이터 세트로 fit()과 transform()을 적용하면 테스트 데이터 세트로는 다시 fit()을 수행하지 않고 학습 데이터 세트로 fit()을 수행한 결과를 이용해 transform() 변환을 적용해야 한다. <br>\n",
    "테스트 데이터로 다시 새로운 스케일링 기준 정보를 만들게 되면 학습 데이터와 테스트 데이터의 스케일링 기준 정보가 달라지기 때문에 올바른 예측 결과를 도출하지 못할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65d7a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성한다.\n",
    "# Scaler 클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array = np.arange(0, 6).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3127e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터 :  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale 된 train_array 데이터 :  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler 객체에 별도이 featrue_range 파라미터 값을 지정하지 않으면 0-1 값으로 변환\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit()하게 되면 train_array 데이터의 최소값이 0, 최대값이 10으로 설정\n",
    "scaler.fit(train_array)\n",
    "\n",
    "# 1/10 scaler로 train_array 데이터 변환, 원본 10 -> 1로 변환된다.\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터 : ', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale 된 train_array 데이터 : ', np.round(train_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8ccaaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터 :  [0 1 2 3 4 5]\n",
      "Scale 된 test_array 데이터 :  [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최소값이 0, 최대값이 5로 설정된다.\n",
    "scaler.fit(test_array)\n",
    "\n",
    "# 1/5 scale로 test_array 데이터 변환, 원본 5 -> 1로 변환된다. \n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "# test_array의 scale 변환 출력\n",
    "print('원본 test_array 데이터 : ', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale 된 test_array 데이터 : ', np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb9230",
   "metadata": {},
   "source": [
    "학습 데이터와 테스트 데이터의 서로 다른 원본값이 동일한 값으로 변환되는 결과를 초래한다. <br>\n",
    "테스트 데이터는 학습 데이터이 스케일링 기준에 따라야 하며, **테스트 데이터의 1 값은 학습 데이터와 동일하게 0.1값으로 변환되어야 한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "043f7358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터 :  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale 된 train_array 데이터 :  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "원본 test_array 데이터 :  [0 1 2 3 4 5]\n",
      "Scale 된 test_array 데이터 :  [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('원본 train_array 데이터 : ', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale 된 train_array 데이터 : ', np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform()만으로 변환해야 한다. \n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('원본 test_array 데이터 : ', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale 된 test_array 데이터 : ', np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a840b8e2",
   "metadata": {},
   "source": [
    "fit_transform()은 fit()과 transform()을 순차적으로 수행하는 메서드이므로 학습 데이터에서는 상관 없지만 **테스트 데이터에서는 절대 사용해서는 안된다.** <br>\n",
    "\n",
    "1. 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터 세트로 분리한다. <br>\n",
    "2. 1번이 불가능하다면 테스트 데이터 변환 시에는 fit()이나 fit_transform()을 적용하지 않고 학습 데이터로 이미 fit()된 Scaler 객체를 이용해 transform()으로 변환한다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
